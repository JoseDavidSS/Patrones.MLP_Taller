{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jose/.local/lib/python3.8/site-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiquetas únicas: [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "# Cargar los datos de MNIST\n",
    "mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
    "\n",
    "# Dividir los datos en características (X) y etiquetas (y)\n",
    "X = mnist.data.astype('float32')\n",
    "y = mnist.target.astype('int32')\n",
    "\n",
    "# Normalizar las características en el rango [0, 1]\n",
    "X /= 255.0\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_entrenamiento, X_prueba, y_entrenamiento, y_prueba = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Etiquetas únicas:\", np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptronMulticapa:\n",
    "    def __init__(self, capas, funciones_activacion, alpha=0.1, epochs=1000):\n",
    "        self.capas = capas\n",
    "        self.funciones_activacion = funciones_activacion\n",
    "        self.funcion_actual = \"s\"\n",
    "        self.alpha = alpha\n",
    "        self.epochs = epochs\n",
    "        self.tiempo_entrenamiento = 0.0\n",
    "        self.num_capas = len(capas)\n",
    "        self.bias = []\n",
    "        self.pesos = []\n",
    "        self.activaciones = []\n",
    "        self.deltas = []\n",
    "\n",
    "        for i in range(1, self.num_capas):\n",
    "            peso = np.random.randn(self.capas[i-1], self.capas[i])\n",
    "            self.pesos.append(peso)\n",
    "            bias = np.random.randn(self.capas[i])\n",
    "            self.bias.append(bias)\n",
    "\n",
    "    def activacion(self, x):\n",
    "        # Función de activación sigmoide\n",
    "        return 1.0 / (1 + np.exp(-x))\n",
    "\n",
    "    def activacion_derivada(self, x):\n",
    "        # Derivada de la función de activación sigmoide\n",
    "        return x * (1 - x)\n",
    "\n",
    "    def activacion_tanh(self, x):\n",
    "        # Función de activación tanh (tangente hiperbólica)\n",
    "        return np.tanh(x)\n",
    "\n",
    "    def activacion_derivada_tanh(self, x):\n",
    "        # Derivada de la función de activación tanh (tangente hiperbólica)\n",
    "        return 1 - np.tanh(x)**2\n",
    "    \n",
    "    def activacion_relu(self, x):\n",
    "        # Función de activación ReLU (Rectified Linear Unit)\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def activacion_derivada_relu(self, x):\n",
    "        # Derivada de la función de activación ReLU (Rectified Linear Unit)\n",
    "        return np.where(x <= 0, 0, 1)\n",
    "\n",
    "    def feedforward(self, X):\n",
    "        self.activaciones = [X]\n",
    "        for i in range(self.num_capas - 1):\n",
    "\n",
    "            # Calcular la salida de la capa actual\n",
    "            if self.funciones_activacion[i] == \"r\": # Para ReLU\n",
    "                activacion = self.activacion_relu(np.dot(self.activaciones[i], self.pesos[i]) + self.bias[i])\n",
    "\n",
    "            elif self.funciones_activacion[i] == \"t\": # Para tanh\n",
    "                activacion = self.activacion_tanh(np.dot(self.activaciones[i], self.pesos[i]) + self.bias[i])\n",
    "\n",
    "            else: # Para sigmoide\n",
    "                activacion = self.activacion(np.dot(self.activaciones[i], self.pesos[i]) + self.bias[i])\n",
    "            \n",
    "            self.activaciones.append(activacion)\n",
    "        return self.activaciones[-1]\n",
    "\n",
    "    def backpropagation(self, X, y):\n",
    "        self.deltas = []\n",
    "        salida = self.activaciones[-1]\n",
    "        error = salida - y\n",
    "        delta = error * self.activacion_derivada(salida)\n",
    "\n",
    "        self.deltas.append(delta)\n",
    "\n",
    "        # Propagar el error hacia atrás a través de la red neuronal\n",
    "        for i in reversed(range(self.num_capas - 2)):\n",
    "\n",
    "            if self.funciones_activacion[i] == \"r\":\n",
    "                delta = np.dot(self.deltas[0], self.pesos[i + 1].T) * self.activacion_derivada_relu(self.activaciones[i + 1])\n",
    "            elif self.funciones_activacion[i] == \"t\":\n",
    "                delta = np.dot(self.deltas[0], self.pesos[i + 1].T) * self.activacion_derivada_tanh(self.activaciones[i + 1])\n",
    "            else:\n",
    "                delta = np.dot(self.deltas[0], self.pesos[i + 1].T) * self.activacion_derivada(self.activaciones[i + 1])\n",
    "            \n",
    "            self.deltas.insert(0, delta)\n",
    "\n",
    "        # Actualizar pesos y bias\n",
    "        for i in range(self.num_capas - 1):\n",
    "            d_peso = np.outer(self.activaciones[i], self.deltas[i])\n",
    "            self.pesos[i] -= self.alpha * d_peso\n",
    "            self.bias[i] -= self.alpha * self.deltas[i]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        tiempo_inicio = time.time()\n",
    "        for _ in range(self.epochs):\n",
    "            for i in range(len(X)):\n",
    "                x = X[i]\n",
    "                y_true = y[i]\n",
    "                self.feedforward(x)\n",
    "                self.backpropagation(x, y_true)\n",
    "        self.tiempo_entrenamiento = time.time() - tiempo_inicio\n",
    "\n",
    "    def predict(self, X):\n",
    "        self.activaciones = [X]\n",
    "        for i in range(self.num_capas - 1):\n",
    "            # Calcular la salida de la capa actual\n",
    "            activacion = self.activacion(np.dot(self.activaciones[i], self.pesos[i]) + self.bias[i])\n",
    "            self.activaciones.append(activacion)\n",
    "        predicciones = np.argmax(self.activaciones[-1], axis=1)\n",
    "        return predicciones\n",
    "    \n",
    "    def score(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        accuracy = np.mean(y_pred == y)\n",
    "        return accuracy\n",
    "    \n",
    "    def metricas(self, y_prueba, y_pred):\n",
    "        recall = recall_score(y_prueba, y_pred, average='macro')\n",
    "        precision = precision_score(y_prueba, y_pred, zero_division=1, average='macro')\n",
    "        accuracy = accuracy_score(y_prueba, y_pred)\n",
    "        f1 = f1_score(y_prueba, y_pred, average='macro')\n",
    "        return recall, precision, accuracy, f1, self.tiempo_entrenamiento\n",
    "    \n",
    "    def imprimir_metricas(self, y_prueba, y_pred):\n",
    "        recall, precision, accuracy, f1, tiempo_entrenamiento = self.metricas(y_prueba, y_pred)\n",
    "        print (\"Recall_______________________: \", recall)\n",
    "        print (\"Precision____________________: \", precision)\n",
    "        print (\"Accuracy_____________________: \", accuracy)\n",
    "        print (\"F1___________________________: \", f1)\n",
    "        print (\"Tiempo de entrenamiento______: \", tiempo_entrenamiento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myMLP (capas_ocultas, funciones_activacion, alpha, epochs):\n",
    "    capas = [784] + capas_ocultas + [10]\n",
    "    funciones_activacion = [\"s\"] + funciones_activacion + [\"s\"]\n",
    "    perceptron = PerceptronMulticapa(capas, funciones_activacion, alpha, epochs)\n",
    "    num_capas = perceptron.num_capas\n",
    "    return perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el perceptrón multicapa\n",
    "capas_ocultas = [8, 10, 61, 30]\n",
    "funciones_activacion = [\"s\", \"r\", \"t\", \"s\"]\n",
    "alpha = 0.1\n",
    "epochs = 2\n",
    "perceptron = myMLP(capas_ocultas, funciones_activacion, alpha, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall_______________________:  0.16256769962892928\n",
      "Precision____________________:  0.7966718034729079\n",
      "Accuracy_____________________:  0.1692142857142857\n",
      "F1___________________________:  0.06383225459392111\n",
      "Tiempo de entrenamiento______:  17.757840633392334\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el perceptrón multicapa\n",
    "X_entrenamiento = X_entrenamiento.to_numpy()\n",
    "\n",
    "perceptron.fit(X_entrenamiento, np.eye(10)[y_entrenamiento])\n",
    "\n",
    "# Hacer predicciones sobre el conjunto de prueba\n",
    "predicciones = perceptron.predict(X_prueba)\n",
    "\n",
    "# Imprimir métricas\n",
    "perceptron.imprimir_metricas(y_prueba, predicciones)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
